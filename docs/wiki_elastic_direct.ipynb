{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elasticsearch: indexing and queries\n",
    "\n",
    "### Resources\n",
    "\n",
    "* https://marcobonzanini.com/2015/06/22/tuning-relevance-in-elasticsearch-with-custom-boosting/\n",
    "* https://readthedocs.org/projects/elasticsearch-dsl/downloads/pdf/stable/\n",
    "* https://www.elastic.co/blog/easier-relevance-tuning-elasticsearch-7-0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "from elasticsearch import Elasticsearch\n",
    "import wikipediaapi\n",
    "from slugify import slugify\n",
    "from pprint import pprint\n",
    "import wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search Wikipedia articles by category and add to Elasticsearch database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Elasticsearch(\"http://localhost:9200\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_wiki = wikipediaapi.Wikipedia('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = \"Coronaviridae\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*: Coronaviridae (ns: 0)\n",
      "*: Coronavirus (ns: 0)\n",
      "*: Bat-borne virus (ns: 0)\n",
      "*: Chinese coronavirus (ns: 0)\n",
      "*: Coronavirinae (ns: 0)\n",
      "*: Coronavirus 3' UTR pseudoknot (ns: 0)\n",
      "*: Coronavirus frameshifting stimulation element (ns: 0)\n",
      "*: Coronavirus packaging signal (ns: 0)\n",
      "*: Coronavirus SL-III cis-acting replication element (ns: 0)\n",
      "*: Novel coronavirus (ns: 0)\n",
      "*: Coronavirus disease (ns: 0)\n",
      "*: SHC014-CoV (ns: 0)\n",
      "*: Slippery sequence (ns: 0)\n",
      "*: Category:Alphacoronaviruses (ns: 14)\n",
      "**: Alphacoronavirus (ns: 0)\n",
      "**: Canine coronavirus (ns: 0)\n",
      "**: Duvinacovirus (ns: 0)\n",
      "**: Feline coronavirus (ns: 0)\n",
      "**: Feline infectious peritonitis virus (ns: 0)\n",
      "**: Human coronavirus 229E (ns: 0)\n",
      "**: Human coronavirus NL63 (ns: 0)\n",
      "**: Miniopterus bat coronavirus 1 (ns: 0)\n",
      "**: Miniopterus bat coronavirus HKU8 (ns: 0)\n",
      "**: Minunacovirus (ns: 0)\n",
      "**: Pedacovirus (ns: 0)\n",
      "**: Porcine epidemic diarrhea virus (ns: 0)\n",
      "**: Rhinacovirus (ns: 0)\n",
      "**: Rhinolophus bat coronavirus HKU2 (ns: 0)\n",
      "**: Scotophilus bat coronavirus 512 (ns: 0)\n",
      "**: Setracovirus (ns: 0)\n",
      "**: Swine acute diarrhea syndrome coronavirus (ns: 0)\n",
      "**: Transmissible gastroenteritis virus (ns: 0)\n",
      "*: Category:Betacoronaviruses (ns: 14)\n",
      "**: Betacoronavirus (ns: 0)\n",
      "**: Betacoronavirus 1 (ns: 0)\n",
      "**: Bovine coronavirus (ns: 0)\n",
      "**: Embecovirus (ns: 0)\n",
      "**: Human coronavirus HKU1 (ns: 0)\n",
      "**: Human coronavirus OC43 (ns: 0)\n",
      "**: Merbecovirus (ns: 0)\n",
      "**: Murine coronavirus (ns: 0)\n",
      "**: Nobecovirus (ns: 0)\n",
      "**: Rousettus bat coronavirus HKU9 (ns: 0)\n",
      "**: Sarbecovirus (ns: 0)\n",
      "**: Category:Merbecovirus (ns: 14)\n",
      "**: Category:Sarbecovirus (ns: 14)\n",
      "*: Category:Deltacoronaviruses (ns: 14)\n",
      "**: Deltacoronavirus (ns: 0)\n",
      "**: Bulbul coronavirus HKU11 (ns: 0)\n",
      "**: Buldecovirus (ns: 0)\n",
      "**: Coronavirus HKU15 (ns: 0)\n",
      "*: Category:Gammacoronaviruses (ns: 14)\n",
      "**: Gammacoronavirus (ns: 0)\n",
      "**: Avian coronavirus (ns: 0)\n",
      "**: Beluga whale coronavirus SW1 (ns: 0)\n",
      "**: Cegacovirus (ns: 0)\n",
      "**: Igacovirus (ns: 0)\n",
      "**: Infectious bronchitis virus D-RNA (ns: 0)\n"
     ]
    }
   ],
   "source": [
    "def print_categorymembers(categorymembers, level=0, max_level=1):\n",
    "        for c in categorymembers.values():\n",
    "            print(\"%s: %s (ns: %d)\" % (\"*\" * (level + 1), c.title, c.ns))\n",
    "            if c.ns == wikipediaapi.Namespace.CATEGORY and level < max_level:\n",
    "                print_categorymembers(c.categorymembers, level=level + 1, max_level=max_level)\n",
    "\n",
    "\n",
    "cat = wiki_wiki.page(f\"Category:{category}\")\n",
    "print_categorymembers(cat.categorymembers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Document:\n",
    "    \n",
    "    def __init__(self, title, text, source, page_id, category=category):\n",
    "\n",
    "        self.category = category\n",
    "        self.title = title\n",
    "        self.text = text\n",
    "        self.source = source\n",
    "        self.page_id = page_id\n",
    "        \n",
    "        self.body = {\"title\": self.title,\n",
    "                     \"text\": self.text,\n",
    "                     \"source\":self.source,\n",
    "                     \"page_id\": self.page_id}\n",
    "\n",
    "    def insert(self):\n",
    "        \n",
    "        slug = slugify(self.category)\n",
    "        \n",
    "        if client.search(index=slug, \n",
    "                         body={\"query\": \n",
    "                                 {\"match\": \n",
    "                                  {\"page_id\": self.page_id}\n",
    "                                 }\n",
    "                                }) == None:\n",
    "            try:\n",
    "        \n",
    "                \n",
    "                client.index(index=slug, body=self.body)\n",
    "\n",
    "            except Exception as error:\n",
    "                print(f\"Could not create a JSON entry for an article {self.source}\")\n",
    "                \n",
    "        else:\n",
    "            print(f\"Article {self.source} is already in the database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_insert_wiki(category):\n",
    "    \n",
    "    if type(category) is not list: category = [ category ]\n",
    "\n",
    "    wiki_wiki = wikipediaapi.Wikipedia('en')\n",
    "    \n",
    "    for c in category:\n",
    "\n",
    "        cat = wiki_wiki.page(f\"Category:{c}\")\n",
    "\n",
    "        for key in cat.categorymembers.keys():\n",
    "            page = wiki_wiki.page(key)\n",
    "\n",
    "            if not \"Category:\" in page.title:\n",
    "                \n",
    "                doc = Document(page.title, page.text, page.fullurl, page.pageid, category=c)\n",
    "#                 for i in doc.text.split('\\n')[:1]: print(i)\n",
    "                doc.insert()\n",
    "#                 print(f'{doc.title} is entered into elasticsearch database')\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "NotFoundError(404, 'index_not_found_exception', 'no such index [coronaviridae]', coronaviridae, index_or_alias)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-d69da8e8ac96>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msearch_insert_wiki\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcategory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-8-296f6bad1d11>\u001b[0m in \u001b[0;36msearch_insert_wiki\u001b[1;34m(category)\u001b[0m\n\u001b[0;32m     16\u001b[0m                 \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDocument\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfullurl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpageid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m#                 for i in doc.text.split('\\n')[:1]: print(i)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m                 \u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;31m#                 print(f'{doc.title} is entered into elasticsearch database')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-05fe74ff1307>\u001b[0m in \u001b[0;36minsert\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     21\u001b[0m                          body={\"query\": \n\u001b[0;32m     22\u001b[0m                                  {\"match\": \n\u001b[1;32m---> 23\u001b[1;33m                                   \u001b[1;33m{\u001b[0m\u001b[1;34m\"page_id\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpage_id\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m                                  }\n\u001b[0;32m     25\u001b[0m                                 }) == None:\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\nlpia\\lib\\site-packages\\elasticsearch\\client\\utils.py\u001b[0m in \u001b[0;36m_wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     82\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m                     \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapped\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\nlpia\\lib\\site-packages\\elasticsearch\\client\\__init__.py\u001b[0m in \u001b[0;36msearch\u001b[1;34m(self, body, index, doc_type, params)\u001b[0m\n\u001b[0;32m   1546\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1547\u001b[0m         return self.transport.perform_request(\n\u001b[1;32m-> 1548\u001b[1;33m             \u001b[1;34m\"GET\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_make_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdoc_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_search\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1549\u001b[0m         )\n\u001b[0;32m   1550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\nlpia\\lib\\site-packages\\elasticsearch\\transport.py\u001b[0m in \u001b[0;36mperform_request\u001b[1;34m(self, method, url, headers, params, body)\u001b[0m\n\u001b[0;32m    356\u001b[0m                     \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m                     \u001b[0mignore\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mignore\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 358\u001b[1;33m                     \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    359\u001b[0m                 )\n\u001b[0;32m    360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\nlpia\\lib\\site-packages\\elasticsearch\\connection\\http_urllib3.py\u001b[0m in \u001b[0;36mperform_request\u001b[1;34m(self, method, url, params, body, timeout, ignore, headers)\u001b[0m\n\u001b[0;32m    259\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfull_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m             )\n\u001b[1;32m--> 261\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_raise_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    262\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m         self.log_request_success(\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\nlpia\\lib\\site-packages\\elasticsearch\\connection\\base.py\u001b[0m in \u001b[0;36m_raise_error\u001b[1;34m(self, status_code, raw_data)\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         raise HTTP_EXCEPTIONS.get(status_code, TransportError)(\n\u001b[1;32m--> 182\u001b[1;33m             \u001b[0mstatus_code\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror_message\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madditional_info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         )\n\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: NotFoundError(404, 'index_not_found_exception', 'no such index [coronaviridae]', coronaviridae, index_or_alias)"
     ]
    }
   ],
   "source": [
    "search_insert_wiki(category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Stan Lee', 'List of cameo appearances by Stan Lee', 'Stan Lee (disambiguation)', \"Stan Lee's Superhumans\", 'Stan Lee Media', 'Joan Boocock Lee', 'Stan Lee Foundation', 'Linda Lee Cadwell', \"Stan Lee's Mighty 7\", 'Stan Lee Meets...']\n"
     ]
    }
   ],
   "source": [
    "print(wikipedia.search(\"Stan Lee\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Return the list of all indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kibana_sample_data_ecommerce': {'aliases': {}},\n",
       " 'american-science-fiction-television-series': {'aliases': {}},\n",
       " 'marvel-comics-editors-in-chief': {'aliases': {}},\n",
       " '.kibana_1': {'aliases': {'.kibana': {}}},\n",
       " '.apm-agent-configuration': {'aliases': {}},\n",
       " 'american-comics-writers': {'aliases': {}},\n",
       " 'machine-learning': {'aliases': {}},\n",
       " 'science-fiction-television': {'aliases': {}},\n",
       " 'presidents-of-the-united-states': {'aliases': {}},\n",
       " 'marvel-comics': {'aliases': {}},\n",
       " '.kibana_task_manager_1': {'aliases': {'.kibana_task_manager': {}}},\n",
       " 'kibana_sample_data_flights': {'aliases': {}},\n",
       " 'natural-language-processing': {'aliases': {}}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.indices.get_alias(\"*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic free text search query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example document search:\n",
    "\n",
    "def search(text, index=''):\n",
    "    return client.search(index=index, \n",
    "                         body={\"query\": \n",
    "                                 {\"match\": \n",
    "                                  {\"text\": text}\n",
    "                                 }\n",
    "                                }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if the wikipedia article already exists in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_page_id(page_id, index=''):\n",
    "    return client.search(index=index, \n",
    "                         body={\"query\": \n",
    "                                 {\"match\": \n",
    "                                  {\"page_id\": page_id}\n",
    "                                 }\n",
    "                                }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevant articles:\n",
      "===================\n",
      "Early life and career\n",
      "Obama was born on August 4, 1961, at Kapiolani Medical Center for Women and Children in Honolulu, Hawaii. He is the only president born outside the contiguous 48 states. He was born to an American mother of European descent and an African father. His mother, Ann Dunham (1942–1995), was born in Wichita, Kansas; she was mostly of English descent, with some German, Irish, Scottish, Swiss, and Welsh ancestry. (In July 2012, Ancestry.com found a strong likelihood that Stanley Ann Dunham was descended from John Punch, an enslaved African man who lived in the Colony of Virginia during the seventeenth century.) His father, Barack Obama Sr. (1936–1982), was a married Luo Kenyan from Nyang'oma Kogelo. Obama's parents met in 1960 in a Russian language class at the University of Hawaii at Manoa, where his father was a foreign student on a scholarship. The couple married in Wailuku, Hawaii, on February 2, 1961, six months before Obama was born.In late August 1961, a few weeks after he was born, Barack and his mother moved to the University of Washington in Seattle, where they lived for a year. During that time, the elder Obama completed his undergraduate degree in economics in Hawaii, graduating in June 1962. He left to attend graduate school on a scholarship at Harvard University, where he earned an M.A. in economics. Obama's parents divorced in March 1964. Obama Sr. returned to Kenya in 1964, where he married for a third time and worked for the Kenyan government as the Senior Economic Analyst in the Ministry of Finance. He visited his son in Hawaii only once, at Christmas 1971, before he was killed in an automobile accident in 1982, when Obama was 21 years old. Recalling his early childhood, Obama said, \"That my father looked nothing like the people around me—that he was black as pitch, my mother white as milk—barely registered in my mind.\" He described his struggles as a young adult to reconcile social perceptions of his multiracial heritage.\n",
      "534366\n",
      "Caught!\n"
     ]
    }
   ],
   "source": [
    "def test_pageid():\n",
    "    res = check_page_id('534366')\n",
    "    \n",
    "    print('Relevant articles:')\n",
    "    print('===================')\n",
    "    for doc in res['hits']['hits']:\n",
    "        print(doc['_source']['text'].split('\\n\\n')[1])\n",
    "        print(doc['_source']['page_id'])\n",
    "\n",
    "x = test_pageid()\n",
    "if x==None:\n",
    "    print(\"Caught!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improving relevance of search results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"When Barack Obama was inaugurated?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevant articles:\n",
      "===================\n",
      "Result 0:\n",
      "Title: Jeff Mariotte\n",
      "Relevance score 12.389853\n",
      "Result 1:\n",
      "Title: Named entity\n",
      "Relevance score 12.173271\n",
      "Result 2:\n",
      "Title: Ta-Nehisi Coates\n",
      "Relevance score 11.393703\n",
      "Result 3:\n",
      "Title: Amber Benson\n",
      "Relevance score 9.310086\n",
      "Result 4:\n",
      "Title: Eric Millikin\n",
      "Relevance score 8.667373\n",
      "Result 5:\n",
      "Title: Jason Rubin\n",
      "Relevance score 8.582391\n",
      "Result 6:\n",
      "Title: Information extraction\n",
      "Relevance score 8.356649\n",
      "Result 7:\n",
      "Title: Rashida Jones\n",
      "Relevance score 7.7038317\n",
      "Result 8:\n",
      "Title: Barack Obama\n",
      "Relevance score 7.4432054\n",
      "Result 9:\n",
      "Title: Alex Ross\n",
      "Relevance score 6.7125754\n"
     ]
    }
   ],
   "source": [
    "def test_search(question):\n",
    "    res = search(text=question)\n",
    "\n",
    "    print('Relevant articles:')\n",
    "    print('===================')\n",
    "\n",
    "    for i, doc in enumerate(res['hits']['hits']):\n",
    "        print(f'Result {i}:')\n",
    "        print(f\"Title: {doc['_source']['title']}\")    \n",
    "        print(f\"Relevance score {doc['_score']}\")\n",
    "\n",
    "test_search(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_body = \\\n",
    "    {\n",
    "      \"query\": {\n",
    "        \"bool\": {\n",
    "          \"should\": [\n",
    "            {\n",
    "              \"match\": {\n",
    "                \"title\": {\n",
    "                  \"query\": question,\n",
    "                  \"boost\": 3\n",
    "                }\n",
    "              }\n",
    "            },\n",
    "            {\n",
    "              \"match\": { \n",
    "                \"text\": question\n",
    "              }\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "      }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result 0:\n",
      "Title: Barack Obama\n",
      "Relevance score 31.020813\n",
      "Result 1:\n",
      "Title: Jeff Mariotte\n",
      "Relevance score 12.389853\n",
      "Result 2:\n",
      "Title: Named entity\n",
      "Relevance score 12.173271\n",
      "Result 3:\n",
      "Title: Ta-Nehisi Coates\n",
      "Relevance score 11.393703\n",
      "Result 4:\n",
      "Title: Amber Benson\n",
      "Relevance score 9.310086\n",
      "Result 5:\n",
      "Title: Eric Millikin\n",
      "Relevance score 8.667373\n",
      "Result 6:\n",
      "Title: Jason Rubin\n",
      "Relevance score 8.582391\n",
      "Result 7:\n",
      "Title: Information extraction\n",
      "Relevance score 8.356649\n",
      "Result 8:\n",
      "Title: Rashida Jones\n",
      "Relevance score 7.7038317\n",
      "Result 9:\n",
      "Title: Alex Ross\n",
      "Relevance score 6.7125754\n"
     ]
    }
   ],
   "source": [
    "search_result = client.search(index='', body=query_body)\n",
    "for i, doc in enumerate(search_result['hits']['hits']):\n",
    "    print(f'Result {i}:')\n",
    "    print(f\"Title: {doc['_source']['title']}\")    \n",
    "    print(f\"Relevance score {doc['_score']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result 0:\n",
      "Title: Barack Obama\n",
      "Relevance score 31.020813\n",
      "Result 1:\n",
      "Title: Jeff Mariotte\n",
      "Relevance score 12.389853\n",
      "Result 2:\n",
      "Title: Named entity\n",
      "Relevance score 12.173271\n",
      "Result 3:\n",
      "Title: Ta-Nehisi Coates\n",
      "Relevance score 11.393703\n",
      "Result 4:\n",
      "Title: Amber Benson\n",
      "Relevance score 9.310086\n",
      "Result 5:\n",
      "Title: Eric Millikin\n",
      "Relevance score 8.667373\n",
      "Result 6:\n",
      "Title: Jason Rubin\n",
      "Relevance score 8.582391\n",
      "Result 7:\n",
      "Title: Information extraction\n",
      "Relevance score 8.356649\n",
      "Result 8:\n",
      "Title: Rashida Jones\n",
      "Relevance score 7.7038317\n",
      "Result 9:\n",
      "Title: Alex Ross\n",
      "Relevance score 6.7125754\n"
     ]
    }
   ],
   "source": [
    "query_body = \\\n",
    "    {\n",
    "      \"query\": {\n",
    "        \"bool\": {\n",
    "          \"should\": [\n",
    "            {\n",
    "              \"match\": {\n",
    "                \"title\": {\n",
    "                  \"query\": question,\n",
    "                  \"boost\": 3\n",
    "                }\n",
    "              }\n",
    "            },\n",
    "            {\n",
    "              \"match\": { \n",
    "                \"text\": question\n",
    "              }\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "\n",
    "search_result = client.search(index='', body=query_body)\n",
    "for i, doc in enumerate(search_result['hits']['hits']):\n",
    "    print(f'Result {i}:')\n",
    "    print(f\"Title: {doc['_source']['title']}\")    \n",
    "    print(f\"Relevance score {doc['_score']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-match search without boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result 0:\n",
      "Title: Ta-Nehisi Coates\n",
      "Relevance score 6.412328\n",
      "Result 1:\n",
      "Title: Bill Clinton\n",
      "Relevance score 6.4054484\n",
      "Result 2:\n",
      "Title: Jeff Mariotte\n",
      "Relevance score 5.983801\n",
      "Result 3:\n",
      "Title: Sean Murphy (artist)\n",
      "Relevance score 5.7749376\n",
      "Result 4:\n",
      "Title: Open information extraction\n",
      "Relevance score 5.435918\n",
      "Result 5:\n",
      "Title: Named entity\n",
      "Relevance score 4.9300184\n",
      "Result 6:\n",
      "Title: Information extraction\n",
      "Relevance score 3.9993434\n",
      "Result 7:\n",
      "Title: Rashida Jones\n",
      "Relevance score 3.972412\n",
      "Result 8:\n",
      "Title: Barack Obama\n",
      "Relevance score 3.9296012\n",
      "Result 9:\n",
      "Title: Amber Benson\n",
      "Relevance score 3.8804646\n"
     ]
    }
   ],
   "source": [
    "query_body = \\\n",
    "{\n",
    "  \"query\": {\n",
    "    \"multi_match\" : {\n",
    "      \"query\":    \"Barak Obama\", \n",
    "      \"fields\": [ \"title\", \"text\" ] \n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "search_result = client.search(index='', body=query_body)\n",
    "for i, doc in enumerate(search_result['hits']['hits']):\n",
    "    print(f'Result {i}:')\n",
    "    print(f\"Title: {doc['_source']['title']}\")    \n",
    "    print(f\"Relevance score {doc['_score']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-match search with boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result 0:\n",
      "Title: Stan Hart\n",
      "Relevance score 18.541727\n",
      "Result 1:\n",
      "Title: Stan Sakai\n",
      "Relevance score 18.541727\n",
      "Result 2:\n",
      "Title: Lee Falk\n",
      "Relevance score 15.098925\n",
      "Result 3:\n",
      "Title: Jim Lee\n",
      "Relevance score 15.098925\n",
      "Result 4:\n",
      "Title: Elaine Lee\n",
      "Relevance score 15.098925\n",
      "Result 5:\n",
      "Title: Jae Lee\n",
      "Relevance score 15.098925\n",
      "Result 6:\n",
      "Title: Lee Kohse\n",
      "Relevance score 15.098925\n",
      "Result 7:\n",
      "Title: Lee Weeks\n",
      "Relevance score 15.098925\n",
      "Result 8:\n",
      "Title: Stan Lee\n",
      "Relevance score 14.202862\n",
      "Result 9:\n",
      "Title: Jen Lee (cartoonist)\n",
      "Relevance score 12.673573\n"
     ]
    }
   ],
   "source": [
    "query_body = \\\n",
    "{\n",
    "  \"query\": {\n",
    "    \"multi_match\" : {\n",
    "      \"query\":    question, \n",
    "      \"fields\": [ \"title^3\", \"text\" ] \n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "search_result = client.search(index='', body=query_body)\n",
    "for i, doc in enumerate(search_result['hits']['hits']):\n",
    "    print(f'Result {i}:')\n",
    "    print(f\"Title: {doc['_source']['title']}\")    \n",
    "    print(f\"Relevance score {doc['_score']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result 0:\n",
      "Title: Jim Lee\n",
      "Relevance score 16.174313\n",
      "Result 1:\n",
      "Title: Lee Falk\n",
      "Relevance score 15.261215\n",
      "Result 2:\n",
      "Title: Ralph Macchio (editor)\n",
      "Relevance score 13.557625\n",
      "Result 3:\n",
      "Title: Stan Hart\n",
      "Relevance score 11.0070915\n",
      "Result 4:\n",
      "Title: Stan Sakai\n",
      "Relevance score 10.720789\n",
      "Result 5:\n",
      "Title: Jae Lee\n",
      "Relevance score 10.716596\n",
      "Result 6:\n",
      "Title: Elaine Lee\n",
      "Relevance score 10.5024185\n",
      "Result 7:\n",
      "Title: Jen Lee (cartoonist)\n",
      "Relevance score 10.088491\n",
      "Result 8:\n",
      "Title: Stan Lee\n",
      "Relevance score 9.549194\n",
      "Result 9:\n",
      "Title: Machine learning in video games\n",
      "Relevance score 9.171778\n"
     ]
    }
   ],
   "source": [
    "### Multi-match term\n",
    "\n",
    "query_body = \\\n",
    "    {\n",
    "  \"query\": {\n",
    "      \"bool\": {\n",
    "          \"must\": [\n",
    "              {\"match\": {\"title\": \"when did stan lee become editor-in chief\"}},\n",
    "              {\"match\": {\"text\": \"when did stan lee become editor-in chief\"}}\n",
    "              ]\n",
    "          }\n",
    "      }\n",
    "    }\n",
    "search_result = client.search(index='', body=query_body)\n",
    "for i, doc in enumerate(search_result['hits']['hits']):\n",
    "    print(f'Result {i}:')\n",
    "    print(f\"Title: {doc['_source']['title']}\")    \n",
    "    print(f\"Relevance score {doc['_score']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result 0:\n",
      "Title: Stan Lee\n",
      "Relevance score 4.7342873\n"
     ]
    }
   ],
   "source": [
    "\n",
    "query_body = \\\n",
    "    {\n",
    "      \"query\": {\"match_phrase\": \n",
    "                    {\"title\": \"stan lee\"}\n",
    "               }\n",
    "    }\n",
    "search_result = client.search(index='', body=query_body)\n",
    "for i, doc in enumerate(search_result['hits']['hits']):\n",
    "    print(f'Result {i}:')\n",
    "    print(f\"Title: {doc['_source']['title']}\")    \n",
    "    print(f\"Relevance score {doc['_score']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_body = \\\n",
    "    {\n",
    "        \"query\": {\n",
    "            \"match_phrase\" : {\n",
    "                \"message\" : {\n",
    "                    \"query\" : \"this is a test\",\n",
    "                    \"analyzer\" : \"my_analyzer\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
